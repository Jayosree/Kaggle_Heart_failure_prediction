{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32b95f84",
   "metadata": {},
   "source": [
    "Cardiovascular diseases (CVDs) are the number 1 cause of death globally, taking an estimated 17.9 million lives each year, \n",
    "which accounts for 31% of all deaths worldwide. Heart failure is a common event caused by CVDs. \n",
    "This dataset contains 12 features that can be used to predict mortality by heart failure.\n",
    "\n",
    "Here, task is to create a machine learning model which can predict the mortality by heart faliure based on some health conditions.\n",
    "\n",
    "Data dictionary :\n",
    "The meaning of each column in the data as below\n",
    "\n",
    "age : age\n",
    "\n",
    "anaemia : Decrease of red blood cells or hemoglobin (boolean)\n",
    "\n",
    "creatinine_phosphokinase : Level of the CPK enzyme in the blood (mcg/L)\n",
    "\n",
    "diabetes : If the patient has diabetes (boolean)\n",
    "\n",
    "ejection_fraction : Percentage of blood leaving the heart at each contraction (percentage)\n",
    "\n",
    "high_blood_pressure : If the patient has hypertension (boolean)\n",
    "\n",
    "platelets : Platelets in the blood (kiloplatelets/mL)\n",
    "\n",
    "serum_creatinine : Level of serum creatinine in the blood (mg/dL)\n",
    "\n",
    "serum_sodium : Level of serum sodium in the blood (mEq/L)\n",
    "\n",
    "sex : Woman or man (binary)\n",
    "\n",
    "smoking : If the patient smokes or not (boolean)\n",
    "\n",
    "time : Follow-up period (days)\n",
    "\n",
    "DEATH_EVENT : If the patient deceased during the follow-up period (boolean) ---> Target Variable\n",
    "\n",
    "\n",
    "Data source : https://www.kaggle.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6291bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24147fd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0  75.0        0                       582         0                 20   \n",
       "1  55.0        0                      7861         0                 38   \n",
       "2  65.0        0                       146         0                 20   \n",
       "3  50.0        1                       111         0                 20   \n",
       "4  65.0        1                       160         1                 20   \n",
       "\n",
       "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                    1  265000.00               1.9           130    1   \n",
       "1                    0  263358.03               1.1           136    1   \n",
       "2                    0  162000.00               1.3           129    1   \n",
       "3                    0  210000.00               1.9           137    1   \n",
       "4                    0  327000.00               2.7           116    0   \n",
       "\n",
       "   smoking  time  DEATH_EVENT  \n",
       "0        0     4            1  \n",
       "1        0     6            1  \n",
       "2        1     7            1  \n",
       "3        0     7            1  \n",
       "4        0     8            1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('C:\\\\Users\\\\Jaysree\\\\OneDrive\\\\kaggle\\\\heart_failure_clinical_records_dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c54855ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes',\n",
       "       'ejection_fraction', 'high_blood_pressure', 'platelets',\n",
       "       'serum_creatinine', 'serum_sodium', 'sex', 'smoking', 'time',\n",
       "       'DEATH_EVENT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "072a44b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 299 entries, 0 to 298\n",
      "Data columns (total 13 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   age                       299 non-null    float64\n",
      " 1   anaemia                   299 non-null    int64  \n",
      " 2   creatinine_phosphokinase  299 non-null    int64  \n",
      " 3   diabetes                  299 non-null    int64  \n",
      " 4   ejection_fraction         299 non-null    int64  \n",
      " 5   high_blood_pressure       299 non-null    int64  \n",
      " 6   platelets                 299 non-null    float64\n",
      " 7   serum_creatinine          299 non-null    float64\n",
      " 8   serum_sodium              299 non-null    int64  \n",
      " 9   sex                       299 non-null    int64  \n",
      " 10  smoking                   299 non-null    int64  \n",
      " 11  time                      299 non-null    int64  \n",
      " 12  DEATH_EVENT               299 non-null    int64  \n",
      "dtypes: float64(3), int64(10)\n",
      "memory usage: 30.5 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()\n",
    "# 299 entries\n",
    "# 12 columns\n",
    "# no missing values in any column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e633cb9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                          47\n",
       "anaemia                       2\n",
       "creatinine_phosphokinase    208\n",
       "diabetes                      2\n",
       "ejection_fraction            17\n",
       "high_blood_pressure           2\n",
       "platelets                   176\n",
       "serum_creatinine             40\n",
       "serum_sodium                 27\n",
       "sex                           2\n",
       "smoking                       2\n",
       "time                        148\n",
       "DEATH_EVENT                   2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b66d9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anaemia\n",
      "[0 1]\n",
      "\n",
      "\n",
      "diabetes\n",
      "[0 1]\n",
      "\n",
      "\n",
      "high_blood_pressure\n",
      "[1 0]\n",
      "\n",
      "\n",
      "sex\n",
      "[1 0]\n",
      "\n",
      "\n",
      "smoking\n",
      "[0 1]\n",
      "\n",
      "\n",
      "DEATH_EVENT\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "# print(data['age'].unique()) - continuous\n",
    "print('anaemia')\n",
    "print(data['anaemia'].unique()) #categorical\n",
    "\n",
    "# print(data['creatinine_phosphokinase'].unique()) - continuous\n",
    "print('\\n')\n",
    "print('diabetes')\n",
    "print(data['diabetes'].unique()) #categorical\n",
    "\n",
    "# print('ejection_fraction')\n",
    "# print(data['ejection_fraction'].unique()) -continuous\n",
    "print('\\n')\n",
    "print('high_blood_pressure')\n",
    "print(data['high_blood_pressure'].unique()) #categorical\n",
    "# print('\\n')\n",
    "# print(data['platelets'].unique()) -continuous\n",
    "# print('\\n')\n",
    "# print(data['serum_creatinine'].unique()) -continuous\n",
    "\n",
    "# print(data['serum_sodium'].unique()) - continuous\n",
    "print('\\n')\n",
    "print('sex')\n",
    "print(data['sex'].unique())  #categorical\n",
    "\n",
    "print('\\n')\n",
    "print('smoking')\n",
    "print(data['smoking'].unique()) #categorical\n",
    "# print('\\n')\n",
    "print('\\n')\n",
    "# print(data['time'].unique()) - continuous\n",
    "print('DEATH_EVENT')\n",
    "print(data['DEATH_EVENT'].unique())  #categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf7f6aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical_features :  ['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking']\n",
      "continuous_features :  ['age', 'creatinine_phosphokinase', 'ejection_fraction', 'platelets', 'serum_creatinine', 'serum_sodium', 'time']\n",
      "targer variable :  DEATH_EVENT\n"
     ]
    }
   ],
   "source": [
    "categorical_features= ['anaemia', 'diabetes','high_blood_pressure', 'sex', 'smoking']\n",
    "print('categorical_features : ', categorical_features)\n",
    "continuous_features=['age',  'creatinine_phosphokinase', \n",
    "       'ejection_fraction', 'platelets',\n",
    "       'serum_creatinine', 'serum_sodium',  'time']\n",
    "print('continuous_features : ', continuous_features)\n",
    "target_variable='DEATH_EVENT'\n",
    "print('targer variable : ', target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54f39b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>299.0</td>\n",
       "      <td>60.833893</td>\n",
       "      <td>11.894809</td>\n",
       "      <td>40.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anaemia</th>\n",
       "      <td>299.0</td>\n",
       "      <td>0.431438</td>\n",
       "      <td>0.496107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <td>299.0</td>\n",
       "      <td>581.839465</td>\n",
       "      <td>970.287881</td>\n",
       "      <td>23.0</td>\n",
       "      <td>116.5</td>\n",
       "      <td>250.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>7861.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>299.0</td>\n",
       "      <td>0.418060</td>\n",
       "      <td>0.494067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ejection_fraction</th>\n",
       "      <td>299.0</td>\n",
       "      <td>38.083612</td>\n",
       "      <td>11.834841</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <td>299.0</td>\n",
       "      <td>0.351171</td>\n",
       "      <td>0.478136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platelets</th>\n",
       "      <td>299.0</td>\n",
       "      <td>263358.029264</td>\n",
       "      <td>97804.236869</td>\n",
       "      <td>25100.0</td>\n",
       "      <td>212500.0</td>\n",
       "      <td>262000.0</td>\n",
       "      <td>303500.0</td>\n",
       "      <td>850000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serum_creatinine</th>\n",
       "      <td>299.0</td>\n",
       "      <td>1.393880</td>\n",
       "      <td>1.034510</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serum_sodium</th>\n",
       "      <td>299.0</td>\n",
       "      <td>136.625418</td>\n",
       "      <td>4.412477</td>\n",
       "      <td>113.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>299.0</td>\n",
       "      <td>0.648829</td>\n",
       "      <td>0.478136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoking</th>\n",
       "      <td>299.0</td>\n",
       "      <td>0.321070</td>\n",
       "      <td>0.467670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>299.0</td>\n",
       "      <td>130.260870</td>\n",
       "      <td>77.614208</td>\n",
       "      <td>4.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEATH_EVENT</th>\n",
       "      <td>299.0</td>\n",
       "      <td>0.321070</td>\n",
       "      <td>0.467670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          count           mean           std      min  \\\n",
       "age                       299.0      60.833893     11.894809     40.0   \n",
       "anaemia                   299.0       0.431438      0.496107      0.0   \n",
       "creatinine_phosphokinase  299.0     581.839465    970.287881     23.0   \n",
       "diabetes                  299.0       0.418060      0.494067      0.0   \n",
       "ejection_fraction         299.0      38.083612     11.834841     14.0   \n",
       "high_blood_pressure       299.0       0.351171      0.478136      0.0   \n",
       "platelets                 299.0  263358.029264  97804.236869  25100.0   \n",
       "serum_creatinine          299.0       1.393880      1.034510      0.5   \n",
       "serum_sodium              299.0     136.625418      4.412477    113.0   \n",
       "sex                       299.0       0.648829      0.478136      0.0   \n",
       "smoking                   299.0       0.321070      0.467670      0.0   \n",
       "time                      299.0     130.260870     77.614208      4.0   \n",
       "DEATH_EVENT               299.0       0.321070      0.467670      0.0   \n",
       "\n",
       "                               25%       50%       75%       max  \n",
       "age                           51.0      60.0      70.0      95.0  \n",
       "anaemia                        0.0       0.0       1.0       1.0  \n",
       "creatinine_phosphokinase     116.5     250.0     582.0    7861.0  \n",
       "diabetes                       0.0       0.0       1.0       1.0  \n",
       "ejection_fraction             30.0      38.0      45.0      80.0  \n",
       "high_blood_pressure            0.0       0.0       1.0       1.0  \n",
       "platelets                 212500.0  262000.0  303500.0  850000.0  \n",
       "serum_creatinine               0.9       1.1       1.4       9.4  \n",
       "serum_sodium                 134.0     137.0     140.0     148.0  \n",
       "sex                            0.0       1.0       1.0       1.0  \n",
       "smoking                        0.0       0.0       1.0       1.0  \n",
       "time                          73.0     115.0     203.0     285.0  \n",
       "DEATH_EVENT                    0.0       0.0       1.0       1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary statistics for numerical variables\n",
    "data.describe().T\n",
    "\n",
    "# average age is around 60 years, with min 40 years and maximum 95 years\n",
    "\n",
    "# # creatinine_phosphokinase (some enzyme present in blood and measured in mcg/L which is Micrograms per litre)\n",
    "# average of this is 581 mcg/L with minimum being 23.0 and max being 7861.0\n",
    "\n",
    "# ejection_fraction (percentage of blood leaving the heart at each contraction)\n",
    "# average percentage is 38% with min being 14% and max being 80%\n",
    "\n",
    "# platelets (platelets in blood (kiloplatelets/ML))\n",
    "# average being 263358.029264 with min being 25100.0 and max being 850000.0 kiloplatelets\n",
    "\n",
    "# serum_creatinine (level of serum_creatinine in blood (milligrams (mg) per deciliter (dL)))\n",
    "# average being 1.393880 with min being 0.5 and max being 9.4 kiloplatelets\n",
    "\n",
    "# serum_sodium (level of serum sodium in the blood (mEg/L))\n",
    "# average being 136.625418 with min being 113.0 and max being 148.0 kiloplatelets\n",
    "\n",
    "# time(follow-up period) (days)\n",
    "# average being 130 days with min 4 days and max 285 days\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bf53df",
   "metadata": {},
   "source": [
    "# univariate analysis - categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87a34bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as the target variable is categorical will look into that first\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55c6bd07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='DEATH_EVENT'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "GroupedData= data.groupby('DEATH_EVENT').size()\n",
    "GroupedData.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26c4ddb",
   "metadata": {},
   "source": [
    "# univariate analysis of all categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a5b32f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def PlotBarCharts(inpdata, colstoplot):\n",
    "    %matplotlib inline\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    #generating subplots\n",
    "    fig, subplot=plt.subplots(nrows=1,ncols=len(colstoplot), figsize=(15,4))\n",
    "    fig.suptitle('Bar charts of: '+ str(colstoplot))\n",
    "    \n",
    "    for colName,plotNumber in zip(colstoplot,range(len(colstoplot))):\n",
    "        inpdata.groupby(colName).size().plot(kind='bar',color=['red','grey'], ax=subplot[plotNumber])\n",
    "        \n",
    "        \n",
    "PlotBarCharts(inpdata=data, colstoplot= ['anaemia', 'diabetes','high_blood_pressure', 'sex', 'smoking'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71410fe",
   "metadata": {},
   "source": [
    "# univariate analysis for all continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "141d7f7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'age'}>,\n",
       "        <AxesSubplot:title={'center':'creatinine_phosphokinase'}>,\n",
       "        <AxesSubplot:title={'center':'ejection_fraction'}>],\n",
       "       [<AxesSubplot:title={'center':'platelets'}>,\n",
       "        <AxesSubplot:title={'center':'serum_creatinine'}>,\n",
       "        <AxesSubplot:title={'center':'serum_sodium'}>],\n",
       "       [<AxesSubplot:title={'center':'time'}>, <AxesSubplot:>,\n",
       "        <AxesSubplot:>]], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.hist(['age',  'creatinine_phosphokinase', \n",
    "       'ejection_fraction', 'platelets',\n",
    "       'serum_creatinine', 'serum_sodium',  'time'], figsize=(18,10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946a3408",
   "metadata": {},
   "source": [
    "### all columns selected but creatinine_phosphokinase, serum_creatinine are right skewed\n",
    "### outlier treatment needs to be done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168a2eb2",
   "metadata": {},
   "source": [
    "# detecting outliers in continuous variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a240d3",
   "metadata": {},
   "source": [
    "#### creating a user defined function to detect outliers in all continuous predictors using IQR method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6caadc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def detect_outliers_iqr(df):\n",
    "    outliers = {}\n",
    "    outliers_count = {}\n",
    "    \n",
    "    for column in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[column]):\n",
    "            data = df[column]\n",
    "            outliers[column] = []\n",
    "            outliers_count[column] = 0 \n",
    "            \n",
    "            data = data.dropna()  # Drop NaN values\n",
    "                \n",
    "            data = sorted(data)\n",
    "            q1 = np.percentile(data, 25)\n",
    "            q3 = np.percentile(data, 75)\n",
    "            iqr = q3 - q1\n",
    "            \n",
    "            lower_bound = q1 - (1.5 * iqr)\n",
    "            upper_bound = q3 + (1.5 * iqr)\n",
    "            \n",
    "            for value in data:\n",
    "                if value < lower_bound or value > upper_bound:\n",
    "                    outliers[column].append(value)\n",
    "                    outliers_count[column] += 1   # Increment count for each outlier\n",
    "    return outliers,outliers_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67d7cda5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers:\n",
      "{'age': [], 'creatinine_phosphokinase': [1380, 1419, 1548, 1610, 1688, 1767, 1808, 1820, 1846, 1876, 1896, 2017, 2060, 2261, 2281, 2334, 2413, 2442, 2522, 2656, 2695, 2794, 3964, 3966, 4540, 5209, 5882, 7702, 7861], 'ejection_fraction': [70, 80], 'platelets': [25100.0, 47000.0, 51000.0, 62000.0, 70000.0, 73000.0, 75000.0, 448000.0, 451000.0, 451000.0, 454000.0, 461000.0, 481000.0, 497000.0, 504000.0, 507000.0, 533000.0, 543000.0, 621000.0, 742000.0, 850000.0], 'serum_creatinine': [2.2, 2.3, 2.3, 2.3, 2.4, 2.4, 2.5, 2.5, 2.5, 2.7, 2.7, 2.7, 2.9, 3.0, 3.0, 3.2, 3.4, 3.5, 3.5, 3.7, 3.8, 4.0, 4.4, 5.0, 5.8, 6.1, 6.8, 9.0, 9.4], 'serum_sodium': [113, 116, 121, 124], 'time': []}\n",
      "\n",
      "Outliers Count:\n",
      "{'age': 0, 'creatinine_phosphokinase': 29, 'ejection_fraction': 2, 'platelets': 21, 'serum_creatinine': 29, 'serum_sodium': 4, 'time': 0}\n"
     ]
    }
   ],
   "source": [
    "outliers, outliers_count = detect_outliers_iqr(data[continuous_features])\n",
    "print(\"Outliers:\")\n",
    "print(outliers)\n",
    "print(\"\\nOutliers Count:\")\n",
    "print(outliers_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c86d68cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns without outliers :  {'age': 0, 'time': 0}\n"
     ]
    }
   ],
   "source": [
    "# Create a new dictionary containing column names and outlier counts where count is not equal to 0\n",
    "# this process is called dictionary comprehension \n",
    "# (reference link : https://www.geeksforgeeks.org/python-dictionary-comprehension/)\n",
    "columns_without_outliers = {column: count for column, count in outliers_count.items() if count == 0}\n",
    "\n",
    "print('columns without outliers : ',columns_without_outliers)\n",
    "# do not need to treat these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56402054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.boxplot(column='age', vert=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f9f7634",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.boxplot(column='time', vert=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ad4e0a",
   "metadata": {},
   "source": [
    "#### do not have outliers in two predictors i.e., age, time. can use it as it is. But, need to treat the rest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b739400b",
   "metadata": {},
   "source": [
    "# treating outliers of the continuous predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89172bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns with outliers :  {'creatinine_phosphokinase': 29, 'ejection_fraction': 2, 'platelets': 21, 'serum_creatinine': 29, 'serum_sodium': 4}\n"
     ]
    }
   ],
   "source": [
    "# Create a new dictionary containing column names and outlier counts where count is not equal to 0\n",
    "columns_with_outliers = {column: count for column, count in outliers_count.items() if count != 0}\n",
    "\n",
    "print('columns with outliers : ',columns_with_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29daf655",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>20</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7861</td>\n",
       "      <td>38</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146</td>\n",
       "      <td>20</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111</td>\n",
       "      <td>20</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160</td>\n",
       "      <td>20</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   creatinine_phosphokinase  ejection_fraction  platelets  serum_creatinine  \\\n",
       "0                       582                 20  265000.00               1.9   \n",
       "1                      7861                 38  263358.03               1.1   \n",
       "2                       146                 20  162000.00               1.3   \n",
       "3                       111                 20  210000.00               1.9   \n",
       "4                       160                 20  327000.00               2.7   \n",
       "\n",
       "   serum_sodium  \n",
       "0           130  \n",
       "1           136  \n",
       "2           129  \n",
       "3           137  \n",
       "4           116  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers_to_treat=['creatinine_phosphokinase','ejection_fraction','platelets','serum_creatinine',\n",
    "                                'serum_sodium']\n",
    "outliers_to_treat=pd.DataFrame(data[outliers_to_treat])\n",
    "outliers_to_treat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b6161c",
   "metadata": {},
   "source": [
    "#### creating a new dataframe to have the updated values and not to disturn the original value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a532538f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0  75.0        0                       582         0                 20   \n",
       "1  55.0        0                      7861         0                 38   \n",
       "2  65.0        0                       146         0                 20   \n",
       "3  50.0        1                       111         0                 20   \n",
       "4  65.0        1                       160         1                 20   \n",
       "\n",
       "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                    1  265000.00               1.9           130    1   \n",
       "1                    0  263358.03               1.1           136    1   \n",
       "2                    0  162000.00               1.3           129    1   \n",
       "3                    0  210000.00               1.9           137    1   \n",
       "4                    0  327000.00               2.7           116    0   \n",
       "\n",
       "   smoking  time  DEATH_EVENT  \n",
       "0        0     4            1  \n",
       "1        0     6            1  \n",
       "2        1     7            1  \n",
       "3        0     7            1  \n",
       "4        0     8            1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_data=data\n",
    "updated_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4239de",
   "metadata": {},
   "source": [
    "#### creating a user defined funtion to treat the outliers using capping and flooring method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0d7b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_treatment(df):\n",
    "    new = {}  # Initialize a dictionary to store outlier-treated values for each column\n",
    "    for column in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[column]):\n",
    "            data = df[column]\n",
    "            new[column] = []\n",
    "            \n",
    "            data = data.dropna()  # Drop NaN values\n",
    "            \n",
    "            tenth_percentile = np.percentile(data, 10)\n",
    "            ninetieth_percentile = np.percentile(data, 90)\n",
    "            \n",
    "            for value in data:\n",
    "                if value < tenth_percentile:\n",
    "                    value = tenth_percentile\n",
    "                    new[column].append(value)\n",
    "                elif value > ninetieth_percentile:\n",
    "                    value = ninetieth_percentile\n",
    "                    new[column].append(value)\n",
    "                elif value >= tenth_percentile and value <= ninetieth_percentile:\n",
    "                    new[column].append(value)\n",
    "    \n",
    "    # Create a DataFrame from the new dictionary and return it\n",
    "    return pd.DataFrame(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a91a6f9a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['creatinine_phosphokinase', 'ejection_fraction', 'platelets',\n",
      "       'serum_creatinine', 'serum_sodium'],\n",
      "      dtype='object')\n",
      "   creatinine_phosphokinase  ejection_fraction  platelets  serum_creatinine  \\\n",
      "0                     582.0               25.0  265000.00               1.9   \n",
      "1                    1203.8               38.0  263358.03               1.1   \n",
      "2                     146.0               25.0  162000.00               1.3   \n",
      "3                     111.0               25.0  210000.00               1.9   \n",
      "4                     160.0               25.0  327000.00               2.1   \n",
      "\n",
      "   serum_sodium  \n",
      "0         132.0  \n",
      "1         136.0  \n",
      "2         132.0  \n",
      "3         137.0  \n",
      "4         132.0  \n"
     ]
    }
   ],
   "source": [
    "post_treatment_data=outlier_treatment(outliers_to_treat)\n",
    "print(post_treatment_data.columns)\n",
    "print(post_treatment_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e919319a",
   "metadata": {},
   "source": [
    "#### replacing the values in the updated dataset after treating outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cec592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_data[['creatinine_phosphokinase', 'ejection_fraction', 'platelets',\n",
    "       'serum_creatinine', 'serum_sodium']]=post_treatment_data[['creatinine_phosphokinase', 'ejection_fraction', 'platelets',\n",
    "       'serum_creatinine', 'serum_sodium']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a44d66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers:\n",
      "{'age': [], 'creatinine_phosphokinase': [], 'ejection_fraction': [], 'platelets': [], 'serum_creatinine': [], 'serum_sodium': [], 'time': []}\n",
      "\n",
      "Outliers Count:\n",
      "{'age': 0, 'creatinine_phosphokinase': 0, 'ejection_fraction': 0, 'platelets': 0, 'serum_creatinine': 0, 'serum_sodium': 0, 'time': 0}\n"
     ]
    }
   ],
   "source": [
    "outliers, outliers_count = detect_outliers_iqr(updated_data[continuous_features])\n",
    "print(\"Outliers:\")\n",
    "print(outliers)\n",
    "print(\"\\nOutliers Count:\")\n",
    "print(outliers_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df5ee19",
   "metadata": {},
   "source": [
    "#### we do not have outliers or any missing values in any of the continuous predictors anymore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bc0755",
   "metadata": {},
   "source": [
    "# Making categorical variables ML model ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "251e4dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes',\n",
       "       'ejection_fraction', 'high_blood_pressure', 'platelets',\n",
       "       'serum_creatinine', 'serum_sodium', 'sex', 'smoking', 'time',\n",
       "       'DEATH_EVENT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "863670b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anaemia': array([0, 1], dtype=int64),\n",
       " 'diabetes': array([0, 1], dtype=int64),\n",
       " 'high_blood_pressure': array([1, 0], dtype=int64),\n",
       " 'sex': array([1, 0], dtype=int64),\n",
       " 'smoking': array([0, 1], dtype=int64)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values = {col: updated_data[col].unique() for col in categorical_features}\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fc7fd7",
   "metadata": {},
   "source": [
    "#### as all the categorical values are having 0 or 1 as their values, we do not need to treat anything here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1178ce15",
   "metadata": {},
   "source": [
    "# bivariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04448a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'creatinine_phosphokinase',\n",
       " 'ejection_fraction',\n",
       " 'platelets',\n",
       " 'serum_creatinine',\n",
       " 'serum_sodium',\n",
       " 'time']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90101a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['DEATH_EVENT'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693df3f1",
   "metadata": {},
   "source": [
    "### relationship exploration (categorical target variable vs continuous predictors [box plot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6e05876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7b8ea14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 7 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Box plots for Categorical Target Variable \"Rating\" and continuous predictors\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, PlotCanvas=plt.subplots(nrows=1, ncols=len(continuous_features), figsize=(18,5))\n",
    "\n",
    "# Creating box plots for each continuous predictor against the Target Variable \"Rating\"\n",
    "for PredictorCol , i in zip(continuous_features, range(len(continuous_features))):\n",
    "    updated_data.boxplot(column=PredictorCol, by='DEATH_EVENT', figsize=(5,5), vert=True, ax=PlotCanvas[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4576716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DEATH_EVENT'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e5720",
   "metadata": {},
   "source": [
    "# ANOVA TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0346c459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def functionAnova(inpdata,target_variable,continuous_predictor_list):\n",
    "    from scipy.stats import f_oneway\n",
    "    \n",
    "    #creating empty list of final selected preditor\n",
    "    SelectedPredictor = []\n",
    "    NotSelectedPredictor=[]\n",
    "    \n",
    "    print('### ANOVA RESULTS ###  \\n')\n",
    "    \n",
    "    for predictor in continuous_predictor_list:\n",
    "        categorygrouplist= inpdata.groupby(target_variable)[predictor].apply(list)\n",
    "        AnovaResults=f_oneway(*categorygrouplist)\n",
    "        \n",
    "        if (AnovaResults[1]<0.05):\n",
    "            print(predictor, ' is correlated with ',target_variable, '|P-value:', AnovaResults[1])\n",
    "            SelectedPredictor.append(predictor)\n",
    "        \n",
    "        else:\n",
    "            print(predictor, ' is not correlated with ', target_variable, '|P-value:', AnovaResults[1])\n",
    "            NotSelectedPredictor.append(predictor)\n",
    "            \n",
    "    print('\\nSelected :', SelectedPredictor)\n",
    "    print('Not selected :', NotSelectedPredictor)\n",
    "    #return (SelectedPredictor, NotSelectedPredictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "147d7d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### ANOVA RESULTS ###  \n",
      "\n",
      "age  is correlated with  DEATH_EVENT |P-value: 8.916762946533792e-06\n",
      "creatinine_phosphokinase  is not correlated with  DEATH_EVENT |P-value: 0.9145714794980525\n",
      "ejection_fraction  is correlated with  DEATH_EVENT |P-value: 1.5980908360922697e-05\n",
      "platelets  is not correlated with  DEATH_EVENT |P-value: 0.5253974908754828\n",
      "serum_creatinine  is correlated with  DEATH_EVENT |P-value: 1.6450679843063498e-12\n",
      "serum_sodium  is correlated with  DEATH_EVENT |P-value: 0.0001753632202723875\n",
      "time  is correlated with  DEATH_EVENT |P-value: 9.122223384926926e-23\n",
      "\n",
      "Selected : ['age', 'ejection_fraction', 'serum_creatinine', 'serum_sodium', 'time']\n",
      "Not selected : ['creatinine_phosphokinase', 'platelets']\n"
     ]
    }
   ],
   "source": [
    "functionAnova(inpdata=updated_data, target_variable='DEATH_EVENT',continuous_predictor_list=continuous_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e33b07ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>132.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>132.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  ejection_fraction  serum_creatinine  serum_sodium  time\n",
       "0  75.0               25.0               1.9         132.0     4\n",
       "1  55.0               38.0               1.1         136.0     6\n",
       "2  65.0               25.0               1.3         132.0     7\n",
       "3  50.0               25.0               1.9         137.0     7\n",
       "4  65.0               25.0               2.1         132.0     8"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_continuous_predictors=pd.DataFrame(updated_data[['age', 'ejection_fraction', 'serum_creatinine', 'serum_sodium', 'time']])\n",
    "selected_continuous_predictors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3631f48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2testfunction(inpdata,target_variable,categoricalcolslist):\n",
    "    selected_predictors=[]\n",
    "    not_selected_predictors=[]\n",
    "    \n",
    "    for predictor in categoricalcolslist:\n",
    "        from scipy.stats import chi2_contingency\n",
    "        crosstab_result=pd.crosstab(index=inpdata[predictor], columns=target_variable)\n",
    "        chi2_result=chi2_contingency(crosstab_result)\n",
    "        \n",
    "        if chi2_result[1]<0.05:\n",
    "            print(predictor, ' is correlated with ', target_variable, '| P-value : ', chi2_result[1])\n",
    "            selected_predictors.append(predictor)\n",
    "        else:\n",
    "            print(predictor, ' is not correlated with ', target_variable, '| P-value : ', chi2_result[1])\n",
    "            not_selected_predictors.append(predictor)\n",
    "            \n",
    "    print('\\nselected : ', selected_predictors)\n",
    "    print('not selected : ', not_selected_predictors)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "207af87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anaemia  is not correlated with  DEATH_EVENT | P-value :  1.0\n",
      "diabetes  is not correlated with  DEATH_EVENT | P-value :  1.0\n",
      "high_blood_pressure  is not correlated with  DEATH_EVENT | P-value :  1.0\n",
      "sex  is not correlated with  DEATH_EVENT | P-value :  1.0\n",
      "smoking  is not correlated with  DEATH_EVENT | P-value :  1.0\n",
      "\n",
      "selected :  []\n",
      "not selected :  ['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking']\n"
     ]
    }
   ],
   "source": [
    "chi2testfunction(inpdata=updated_data,target_variable=target_variable,categoricalcolslist=categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b82b3e5",
   "metadata": {},
   "source": [
    "we have only final continuous predictors as predictors as all the categorical predictors are not having \n",
    "any relation with the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe543f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'ejection_fraction', 'serum_creatinine', 'serum_sodium', 'time']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictors=['age', 'ejection_fraction', 'serum_creatinine', 'serum_sodium', 'time']\n",
    "final_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf24ad4",
   "metadata": {},
   "source": [
    "# splitting the data into Training and testing sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4b47d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=updated_data[final_predictors].values\n",
    "y=updated_data[target_variable].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a851360",
   "metadata": {},
   "source": [
    " #### splitting the data into training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "89e358a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3, random_state=101)\n",
    "\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c49d5e",
   "metadata": {},
   "source": [
    "# standardization/normalization of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62d5f31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.63636364 0.         0.84615385 0.         0.        ]\n",
      " [0.27272727 0.37142857 0.23076923 0.43478261 0.00711744]\n",
      " [0.45454545 0.         0.38461538 0.         0.01067616]\n",
      " ...\n",
      " [0.09090909 1.         0.         0.65217391 0.97508897]\n",
      " [0.09090909 0.37142857 0.46153846 0.86956522 0.98220641]\n",
      " [0.18181818 0.57142857 0.61538462 0.43478261 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# standard_PredictorScalar=StandardScaler()\n",
    "minmax_PredictorScalar = MinMaxScaler()\n",
    "\n",
    "# standard_PredictorScalarFit=standard_PredictorScalar.fit(x)\n",
    "minmax_PredictorScalarFit= minmax_PredictorScalar.fit(x)\n",
    "# having more accuracy in minmax so choosing that one\n",
    "x=minmax_PredictorScalarFit.transform(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de4be0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209, 5)\n",
      "(209,)\n",
      "(90, 5)\n",
      "(90,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.45454545, 0.71428571, 0.15384615, 0.86956522, 0.08896797],\n",
       "       [0.27272727, 0.37142857, 0.23076923, 0.43478261, 0.00711744],\n",
       "       [0.41818182, 1.        , 0.38461538, 1.        , 0.36654804],\n",
       "       ...,\n",
       "       [0.45454545, 1.        , 0.        , 0.86956522, 0.26690391],\n",
       "       [0.09090909, 0.28571429, 0.15384615, 1.        , 0.20284698],\n",
       "       [0.4       , 0.        , 0.07692308, 0.86956522, 0.02135231]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.3, random_state=101)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e6931e",
   "metadata": {},
   "source": [
    "# logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67acd1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6915dca5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, penalty='l1', solver='saga')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92        62\n",
      "           1       0.85      0.79      0.81        28\n",
      "\n",
      "    accuracy                           0.89        90\n",
      "   macro avg       0.88      0.86      0.87        90\n",
      "weighted avg       0.89      0.89      0.89        90\n",
      "\n",
      "[[58  4]\n",
      " [ 6 22]]\n"
     ]
    }
   ],
   "source": [
    "# choose parameter penalty=l1 and c=1\n",
    "logistic_regression_model= LogisticRegression(C=1,penalty='l1', solver='saga')\n",
    "print(logistic_regression_model)\n",
    "\n",
    "# creating the model on training data\n",
    "logistic_regression=logistic_regression_model.fit(x_train,y_train)\n",
    "logistic_regression_prediction=logistic_regression.predict(x_test)\n",
    "\n",
    "# measuring accuracy\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test,logistic_regression_prediction))\n",
    "print(metrics.confusion_matrix(y_test,logistic_regression_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41057c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on Testing Sample Data: 0.89\n",
      "\n",
      "Accuracy values for 10-fold Cross Validation:\n",
      " [0.70300334 0.80542986 0.87037037 0.79365079 0.93121693 0.89858793\n",
      " 0.85341615 0.89333333 0.648      0.56298381]\n",
      "\n",
      "Final Average Accuracy of the logistic_regression model: 0.8\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# Printing the Overall Accuracy of the model\n",
    "F1_Score=metrics.f1_score(y_test, logistic_regression_prediction, average='weighted')\n",
    "print('Accuracy of the model on Testing Sample Data:', round(F1_Score,2))\n",
    "\n",
    "# Importing cross validation function from sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Running 10-Fold Cross validation on a given algorithm\n",
    "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
    "logistic_regression_Accuracy_Values=cross_val_score(logistic_regression, x , y, cv=10, scoring='f1_weighted')\n",
    "print('\\nAccuracy values for 10-fold Cross Validation:\\n',logistic_regression_Accuracy_Values)\n",
    "print('\\nFinal Average Accuracy of the logistic_regression model:', round(logistic_regression_Accuracy_Values.mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "66b24c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "[CV 1/5] END ..........C=0.001, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END ..........C=0.001, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END ..........C=0.001, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END ..........C=0.001, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END ..........C=0.001, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END ..........C=0.001, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END ..........C=0.001, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END ..........C=0.001, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END ..........C=0.001, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END ..........C=0.001, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END ..............C=0.001, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ..............C=0.001, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ..............C=0.001, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ..............C=0.001, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ..............C=0.001, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END ................C=0.001, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 2/5] END ................C=0.001, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 3/5] END ................C=0.001, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 4/5] END ................C=0.001, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 5/5] END ................C=0.001, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 1/5] END ...............C=0.001, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 2/5] END ...............C=0.001, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 3/5] END ...............C=0.001, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 4/5] END ...............C=0.001, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 5/5] END ...............C=0.001, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 1/5] END ..........C=0.001, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END ..........C=0.001, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END ..........C=0.001, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END ..........C=0.001, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END ..........C=0.001, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END ..........C=0.001, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END ..........C=0.001, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END ..........C=0.001, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END ..........C=0.001, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END ..........C=0.001, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END ..............C=0.001, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ..............C=0.001, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ..............C=0.001, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ..............C=0.001, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ..............C=0.001, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END ................C=0.001, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 2/5] END ................C=0.001, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 3/5] END ................C=0.001, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 4/5] END ................C=0.001, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 5/5] END ................C=0.001, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 1/5] END ...............C=0.001, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 2/5] END ...............C=0.001, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 3/5] END ...............C=0.001, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 4/5] END ...............C=0.001, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 5/5] END ...............C=0.001, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 1/5] END ...........C=0.01, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END ...........C=0.01, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END ...........C=0.01, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END ...........C=0.01, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END ...........C=0.01, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END ...........C=0.01, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END ...........C=0.01, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END ...........C=0.01, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END ...........C=0.01, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END ...........C=0.01, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END ...............C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ...............C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ...............C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ...............C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ...............C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END .................C=0.01, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 2/5] END .................C=0.01, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 3/5] END .................C=0.01, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 4/5] END .................C=0.01, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 5/5] END .................C=0.01, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 1/5] END ................C=0.01, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 2/5] END ................C=0.01, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 3/5] END ................C=0.01, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 4/5] END ................C=0.01, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 5/5] END ................C=0.01, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 1/5] END ...........C=0.01, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END ...........C=0.01, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END ...........C=0.01, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END ...........C=0.01, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END ...........C=0.01, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END ...........C=0.01, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END ...........C=0.01, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END ...........C=0.01, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END ...........C=0.01, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END ...........C=0.01, penalty=l2, solver=newton-cg; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...............C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ...............C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ...............C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ...............C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ...............C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END .................C=0.01, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 2/5] END .................C=0.01, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 3/5] END .................C=0.01, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 4/5] END .................C=0.01, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 5/5] END .................C=0.01, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 1/5] END ................C=0.01, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 2/5] END ................C=0.01, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 3/5] END ................C=0.01, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 4/5] END ................C=0.01, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 5/5] END ................C=0.01, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 1/5] END ............C=0.1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END ............C=0.1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END ............C=0.1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END ............C=0.1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END ............C=0.1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END ............C=0.1, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END ............C=0.1, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END ............C=0.1, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END ............C=0.1, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END ............C=0.1, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END ................C=0.1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ................C=0.1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ................C=0.1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ................C=0.1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ................C=0.1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END ..................C=0.1, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 2/5] END ..................C=0.1, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 3/5] END ..................C=0.1, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 4/5] END ..................C=0.1, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 5/5] END ..................C=0.1, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 1/5] END .................C=0.1, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 2/5] END .................C=0.1, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 3/5] END .................C=0.1, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 4/5] END .................C=0.1, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 5/5] END .................C=0.1, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 1/5] END ............C=0.1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END ............C=0.1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END ............C=0.1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END ............C=0.1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END ............C=0.1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END ............C=0.1, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END ............C=0.1, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END ............C=0.1, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END ............C=0.1, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END ............C=0.1, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END ................C=0.1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ................C=0.1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ................C=0.1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ................C=0.1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ................C=0.1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END ..................C=0.1, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 2/5] END ..................C=0.1, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 3/5] END ..................C=0.1, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 4/5] END ..................C=0.1, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 5/5] END ..................C=0.1, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 1/5] END .................C=0.1, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 2/5] END .................C=0.1, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 3/5] END .................C=0.1, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 4/5] END .................C=0.1, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 5/5] END .................C=0.1, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 1/5] END ..............C=1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END ..............C=1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END ..............C=1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END ..............C=1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END ..............C=1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END ..............C=1, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END ..............C=1, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END ..............C=1, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END ..............C=1, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END ..............C=1, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END ..................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ..................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ..................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ..................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ..................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END ....................C=1, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 2/5] END ....................C=1, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 3/5] END ....................C=1, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 4/5] END ....................C=1, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 5/5] END ....................C=1, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 1/5] END ...................C=1, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 2/5] END ...................C=1, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 3/5] END ...................C=1, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 4/5] END ...................C=1, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 5/5] END ...................C=1, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 1/5] END ..............C=1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END ..............C=1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END ..............C=1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END ..............C=1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END ..............C=1, penalty=l2, solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..............C=1, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END ..............C=1, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END ..............C=1, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END ..............C=1, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END ..............C=1, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END ..................C=1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ..................C=1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ..................C=1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ..................C=1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ..................C=1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END ....................C=1, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 2/5] END ....................C=1, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 3/5] END ....................C=1, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 4/5] END ....................C=1, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 5/5] END ....................C=1, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 1/5] END ...................C=1, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 2/5] END ...................C=1, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 3/5] END ...................C=1, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 4/5] END ...................C=1, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 5/5] END ...................C=1, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 1/5] END .............C=10, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END .............C=10, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END .............C=10, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END .............C=10, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END .............C=10, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END .............C=10, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END .............C=10, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END .............C=10, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END .............C=10, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END .............C=10, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END .................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END .................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END .................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END .................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END .................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END ...................C=10, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 2/5] END ...................C=10, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 3/5] END ...................C=10, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 4/5] END ...................C=10, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 5/5] END ...................C=10, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 1/5] END ..................C=10, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 2/5] END ..................C=10, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 3/5] END ..................C=10, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 4/5] END ..................C=10, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 5/5] END ..................C=10, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 1/5] END .............C=10, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END .............C=10, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END .............C=10, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END .............C=10, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END .............C=10, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END .............C=10, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END .............C=10, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END .............C=10, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END .............C=10, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END .............C=10, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END .................C=10, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END .................C=10, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END .................C=10, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END .................C=10, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END .................C=10, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END ...................C=10, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 2/5] END ...................C=10, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 3/5] END ...................C=10, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 4/5] END ...................C=10, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 5/5] END ...................C=10, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 1/5] END ..................C=10, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 2/5] END ..................C=10, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 3/5] END ..................C=10, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 4/5] END ..................C=10, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 5/5] END ..................C=10, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 1/5] END ............C=100, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END ............C=100, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END ............C=100, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END ............C=100, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END ............C=100, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END ............C=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END ............C=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END ............C=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END ............C=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END ............C=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END ................C=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ................C=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ................C=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ................C=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ................C=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV 1/5] END ..................C=100, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 2/5] END ..................C=100, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 3/5] END ..................C=100, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 4/5] END ..................C=100, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 5/5] END ..................C=100, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV 1/5] END .................C=100, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 2/5] END .................C=100, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 3/5] END .................C=100, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 4/5] END .................C=100, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 5/5] END .................C=100, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV 1/5] END ............C=100, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 2/5] END ............C=100, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 3/5] END ............C=100, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 4/5] END ............C=100, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 5/5] END ............C=100, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV 1/5] END ............C=100, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 2/5] END ............C=100, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 3/5] END ............C=100, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 4/5] END ............C=100, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 5/5] END ............C=100, penalty=l2, solver=newton-cg; total time=   0.0s\n",
      "[CV 1/5] END ................C=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 2/5] END ................C=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 3/5] END ................C=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 4/5] END ................C=100, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV 5/5] END ................C=100, penalty=l2, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..................C=100, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 2/5] END ..................C=100, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 3/5] END ..................C=100, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 4/5] END ..................C=100, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 5/5] END ..................C=100, penalty=l2, solver=sag; total time=   0.0s\n",
      "[CV 1/5] END .................C=100, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 2/5] END .................C=100, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 3/5] END .................C=100, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 4/5] END .................C=100, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV 5/5] END .................C=100, penalty=l2, solver=saga; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.6746806         nan        nan        nan 0.6746806  0.6746806\n",
      " 0.6746806  0.6746806  0.6746806  0.6746806  0.6746806         nan\n",
      "        nan        nan 0.6746806  0.6746806  0.6746806  0.6746806\n",
      " 0.6746806  0.6746806  0.6746806         nan        nan        nan\n",
      " 0.6746806  0.72253194 0.70348432 0.70348432 0.70348432 0.70348432\n",
      " 0.81347271        nan        nan        nan 0.81835075 0.79442509\n",
      " 0.79442509 0.79442509 0.79442509 0.79442509 0.81358885        nan\n",
      "        nan        nan 0.81358885 0.81358885 0.81358885 0.81358885\n",
      " 0.81358885 0.81358885 0.81358885        nan        nan        nan\n",
      " 0.81358885 0.81358885 0.81358885 0.81358885 0.81358885 0.81358885]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "logistic_regression_param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Example values for the regularization strength parameter\n",
    "    'penalty': ['l1','l2'],\n",
    "     'solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "\n",
    "logistic_regression_grid_search=GridSearchCV(logistic_regression, param_grid=logistic_regression_param_grid, cv=5, n_jobs=1, verbose=5)\n",
    "logistic_regression_grid_search_result=logistic_regression_grid_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d966a203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.818351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>100.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.813589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>100.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.813589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>100.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.813589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>100.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.813589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        C penalty     solver  accuracy\n",
       "34    1.0      l1       saga  0.818351\n",
       "59  100.0      l2       saga  0.813589\n",
       "58  100.0      l2        sag  0.813589\n",
       "57  100.0      l2      lbfgs  0.813589\n",
       "56  100.0      l2  newton-cg  0.813589"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=logistic_regression_grid_search_result.cv_results_\n",
    "scores_and_params= pd.DataFrame(results['params'])\n",
    "scores_and_params\n",
    "\n",
    "scores_and_params['accuracy']=pd.DataFrame(results['mean_test_score'], columns=['accuracy'])\n",
    "scores_and_params.sort_values(by= 'accuracy', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddf277f",
   "metadata": {},
   "source": [
    "Precision: Precision measures the proportion of true positive predictions (correctly predicted positive instances) out of all instances predicted as positive.\n",
    "\n",
    "For class 0: Precision is 0.90, indicating that 90% of the instances predicted as class 0 were actually class 0.\n",
    "For class 1: Precision is 0.81, indicating that 81% of the instances predicted as class 1 were actually class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba52e9c5",
   "metadata": {},
   "source": [
    "Recall (Sensitivity): Recall measures the proportion of true positive predictions out of all actual positive instances.\n",
    "\n",
    "For class 0: Recall is 0.92, indicating that 92% of the actual class 0 instances were correctly predicted as class 0.\n",
    "For class 1: Recall is 0.79, indicating that 79% of the actual class 1 instances were correctly predicted as class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e87cf9",
   "metadata": {},
   "source": [
    "F1-score: F1-score is the harmonic mean of precision and recall, providing a balance between the two metrics. It's particularly useful when you have an uneven class distribution.\n",
    "\n",
    "For class 0: F1-score is 0.91.\n",
    "For class 1: F1-score is 0.80.\n",
    "Support: The number of instances of each class in the actual data.\n",
    "\n",
    "Accuracy: Overall accuracy of the model, which is the proportion of correctly predicted instances out of all instances.\n",
    "\n",
    "Accuracy is 0.88, indicating that 88% of the instances were correctly classified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9baf4c5",
   "metadata": {},
   "source": [
    "Confusion Matrix:\n",
    "\n",
    "The confusion matrix provides a tabular summary of the actual vs. predicted classes.\n",
    "\n",
    "In the provided confusion matrix:\n",
    "\n",
    "True Negative (TN): 57 instances were correctly predicted as class 0.\n",
    "False Positive (FP): 5 instances were incorrectly predicted as class 1.\n",
    "False Negative (FN): 6 instances were incorrectly predicted as class 0.\n",
    "True Positive (TP): 22 instances were correctly predicted as class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29f5479",
   "metadata": {},
   "source": [
    "# Decision tree classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3282e2ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=5)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90        62\n",
      "           1       0.77      0.82      0.79        28\n",
      "\n",
      "    accuracy                           0.87        90\n",
      "   macro avg       0.84      0.85      0.85        90\n",
      "weighted avg       0.87      0.87      0.87        90\n",
      "\n",
      "[[55  7]\n",
      " [ 5 23]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "decision_tree_model=tree.DecisionTreeClassifier(max_depth=5,criterion='gini')\n",
    "print(decision_tree_model)\n",
    "\n",
    "decision_tree=decision_tree_model.fit(x_train,y_train)\n",
    "decision_tree_prediction=decision_tree.predict(x_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test,decision_tree_prediction))\n",
    "print(metrics.confusion_matrix(y_test,decision_tree_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c9ace7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on Testing Sample Data: 0.87\n",
      "\n",
      "Accuracy values for 10-fold Cross Validation:\n",
      " [0.16666667 0.77333333 0.8692185  0.8692185  0.83097989 0.80555556\n",
      " 0.50638298 0.78012422 0.60416667 0.56298381]\n",
      "\n",
      "Final Average Accuracy of the decision_tree model: 0.68\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# Printing the Overall Accuracy of the model\n",
    "F1_Score=metrics.f1_score(y_test, decision_tree_prediction, average='weighted')\n",
    "print('Accuracy of the model on Testing Sample Data:', round(F1_Score,2))\n",
    "\n",
    "# Importing cross validation function from sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Running 10-Fold Cross validation on a given algorithm\n",
    "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
    "decision_tree_Accuracy_Values=cross_val_score(decision_tree, x , y, cv=10, scoring='f1_weighted')\n",
    "print('\\nAccuracy values for 10-fold Cross Validation:\\n',decision_tree_Accuracy_Values)\n",
    "print('\\nFinal Average Accuracy of the decision_tree model:', round(decision_tree_Accuracy_Values.mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1d56a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV 1/5] END .................criterion=gini, max_depth=None; total time=   0.0s\n",
      "[CV 2/5] END .................criterion=gini, max_depth=None; total time=   0.0s\n",
      "[CV 3/5] END .................criterion=gini, max_depth=None; total time=   0.0s\n",
      "[CV 4/5] END .................criterion=gini, max_depth=None; total time=   0.0s\n",
      "[CV 5/5] END .................criterion=gini, max_depth=None; total time=   0.0s\n",
      "[CV 1/5] END ....................criterion=gini, max_depth=5; total time=   0.0s\n",
      "[CV 2/5] END ....................criterion=gini, max_depth=5; total time=   0.0s\n",
      "[CV 3/5] END ....................criterion=gini, max_depth=5; total time=   0.0s\n",
      "[CV 4/5] END ....................criterion=gini, max_depth=5; total time=   0.0s\n",
      "[CV 5/5] END ....................criterion=gini, max_depth=5; total time=   0.0s\n",
      "[CV 1/5] END ...................criterion=gini, max_depth=10; total time=   0.0s\n",
      "[CV 2/5] END ...................criterion=gini, max_depth=10; total time=   0.0s\n",
      "[CV 3/5] END ...................criterion=gini, max_depth=10; total time=   0.0s\n",
      "[CV 4/5] END ...................criterion=gini, max_depth=10; total time=   0.0s\n",
      "[CV 5/5] END ...................criterion=gini, max_depth=10; total time=   0.0s\n",
      "[CV 1/5] END ...................criterion=gini, max_depth=15; total time=   0.0s\n",
      "[CV 2/5] END ...................criterion=gini, max_depth=15; total time=   0.0s\n",
      "[CV 3/5] END ...................criterion=gini, max_depth=15; total time=   0.0s\n",
      "[CV 4/5] END ...................criterion=gini, max_depth=15; total time=   0.0s\n",
      "[CV 5/5] END ...................criterion=gini, max_depth=15; total time=   0.0s\n",
      "[CV 1/5] END ..............criterion=entropy, max_depth=None; total time=   0.0s\n",
      "[CV 2/5] END ..............criterion=entropy, max_depth=None; total time=   0.0s\n",
      "[CV 3/5] END ..............criterion=entropy, max_depth=None; total time=   0.0s\n",
      "[CV 4/5] END ..............criterion=entropy, max_depth=None; total time=   0.0s\n",
      "[CV 5/5] END ..............criterion=entropy, max_depth=None; total time=   0.0s\n",
      "[CV 1/5] END .................criterion=entropy, max_depth=5; total time=   0.0s\n",
      "[CV 2/5] END .................criterion=entropy, max_depth=5; total time=   0.0s\n",
      "[CV 3/5] END .................criterion=entropy, max_depth=5; total time=   0.0s\n",
      "[CV 4/5] END .................criterion=entropy, max_depth=5; total time=   0.0s\n",
      "[CV 5/5] END .................criterion=entropy, max_depth=5; total time=   0.0s\n",
      "[CV 1/5] END ................criterion=entropy, max_depth=10; total time=   0.0s\n",
      "[CV 2/5] END ................criterion=entropy, max_depth=10; total time=   0.0s\n",
      "[CV 3/5] END ................criterion=entropy, max_depth=10; total time=   0.0s\n",
      "[CV 4/5] END ................criterion=entropy, max_depth=10; total time=   0.0s\n",
      "[CV 5/5] END ................criterion=entropy, max_depth=10; total time=   0.0s\n",
      "[CV 1/5] END ................criterion=entropy, max_depth=15; total time=   0.0s\n",
      "[CV 2/5] END ................criterion=entropy, max_depth=15; total time=   0.0s\n",
      "[CV 3/5] END ................criterion=entropy, max_depth=15; total time=   0.0s\n",
      "[CV 4/5] END ................criterion=entropy, max_depth=15; total time=   0.0s\n",
      "[CV 5/5] END ................criterion=entropy, max_depth=15; total time=   0.0s\n"
     ]
    }
   ],
   "source": [
    "decision_tree_param_grid = {\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "decision_tree_grid_search=GridSearchCV(decision_tree,param_grid=decision_tree_param_grid, cv=5,n_jobs=1,verbose=5)\n",
    "decision_tree_grid_search_result=decision_tree_grid_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "97eb1287",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gini</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.789779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gini</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.765854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gini</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.765854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.761208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.760976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion  max_depth  accuracy\n",
       "1      gini        5.0  0.789779\n",
       "2      gini       10.0  0.765854\n",
       "3      gini       15.0  0.765854\n",
       "5   entropy        5.0  0.761208\n",
       "0      gini        NaN  0.760976"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=decision_tree_grid_search_result.cv_results_\n",
    "scores_and_params= pd.DataFrame(results['params'])\n",
    "scores_and_params\n",
    "\n",
    "scores_and_params['accuracy']=pd.DataFrame(results['mean_test_score'], columns=['accuracy'])\n",
    "scores_and_params.sort_values(by= 'accuracy', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4c8b0570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the feature importance\n",
    "%matplotlib inline\n",
    "feature_importance=pd.Series(decision_tree.feature_importances_, index=final_predictors)\n",
    "feature_importance.nlargest(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c62ede7",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9b0d3936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(random_state=101)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest_model=RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None,random_state=101)\n",
    "print(random_forest_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c7f9be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest=random_forest_model.fit(x_train,y_train)\n",
    "random_forest_prediction=random_forest.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bd23f142",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88        62\n",
      "           1       0.76      0.68      0.72        28\n",
      "\n",
      "    accuracy                           0.83        90\n",
      "   macro avg       0.81      0.79      0.80        90\n",
      "weighted avg       0.83      0.83      0.83        90\n",
      "\n",
      "[[56  6]\n",
      " [ 9 19]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(y_test,random_forest_prediction))\n",
    "print(metrics.confusion_matrix(y_test,random_forest_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b6b5409f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on Testing Sample Data: 0.83\n",
      "\n",
      "Accuracy values for 10-fold Cross Validation:\n",
      " [0.16666667 0.80555556 0.87037037 0.93460925 0.89858793 0.83097989\n",
      " 0.56024845 0.70909091 0.56       0.56298381]\n",
      "\n",
      "Final Average Accuracy of the random_forest model: 0.69\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# Printing the Overall Accuracy of the model\n",
    "F1_Score=metrics.f1_score(y_test, random_forest_prediction, average='weighted')\n",
    "print('Accuracy of the model on Testing Sample Data:', round(F1_Score,2))\n",
    "\n",
    "# Importing cross validation function from sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Running 10-Fold Cross validation on a given algorithm\n",
    "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
    "random_forest_Accuracy_Values=cross_val_score(random_forest, x , y, cv=10, scoring='f1_weighted')\n",
    "print('\\nAccuracy values for 10-fold Cross Validation:\\n',random_forest_Accuracy_Values)\n",
    "print('\\nFinal Average Accuracy of the random_forest model:', round(random_forest_Accuracy_Values.mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "60095a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_param_grid = {'n_estimators': [100,200,300,500,1000],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "29a50591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV 1/5] END criterion=gini, max_depth=None, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, n_estimators=200; total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, n_estimators=200; total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, n_estimators=200; total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, n_estimators=200; total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, n_estimators=200; total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, n_estimators=300; total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, n_estimators=300; total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, n_estimators=300; total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, n_estimators=300; total time=   0.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, n_estimators=300; total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, n_estimators=500; total time=   0.4s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, n_estimators=500; total time=   0.4s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, n_estimators=500; total time=   0.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, n_estimators=500; total time=   0.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, n_estimators=500; total time=   0.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, n_estimators=1000; total time=   0.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, n_estimators=1000; total time=   0.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, n_estimators=1000; total time=   1.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, n_estimators=1000; total time=   1.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, n_estimators=1000; total time=   1.0s\n",
      "[CV 1/5] END ..criterion=gini, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END ..criterion=gini, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END ..criterion=gini, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END ..criterion=gini, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END ..criterion=gini, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END ..criterion=gini, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV 2/5] END ..criterion=gini, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV 3/5] END ..criterion=gini, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV 4/5] END ..criterion=gini, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV 5/5] END ..criterion=gini, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV 1/5] END ..criterion=gini, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV 2/5] END ..criterion=gini, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV 3/5] END ..criterion=gini, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV 4/5] END ..criterion=gini, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV 5/5] END ..criterion=gini, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV 1/5] END ..criterion=gini, max_depth=5, n_estimators=500; total time=   0.4s\n",
      "[CV 2/5] END ..criterion=gini, max_depth=5, n_estimators=500; total time=   0.4s\n",
      "[CV 3/5] END ..criterion=gini, max_depth=5, n_estimators=500; total time=   0.4s\n",
      "[CV 4/5] END ..criterion=gini, max_depth=5, n_estimators=500; total time=   0.4s\n",
      "[CV 5/5] END ..criterion=gini, max_depth=5, n_estimators=500; total time=   0.4s\n",
      "[CV 1/5] END .criterion=gini, max_depth=5, n_estimators=1000; total time=   0.9s\n",
      "[CV 2/5] END .criterion=gini, max_depth=5, n_estimators=1000; total time=   0.9s\n",
      "[CV 3/5] END .criterion=gini, max_depth=5, n_estimators=1000; total time=   0.9s\n",
      "[CV 4/5] END .criterion=gini, max_depth=5, n_estimators=1000; total time=   0.9s\n",
      "[CV 5/5] END .criterion=gini, max_depth=5, n_estimators=1000; total time=   0.9s\n",
      "[CV 1/5] END .criterion=gini, max_depth=10, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END .criterion=gini, max_depth=10, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END .criterion=gini, max_depth=10, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END .criterion=gini, max_depth=10, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END .criterion=gini, max_depth=10, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END .criterion=gini, max_depth=10, n_estimators=200; total time=   0.1s\n",
      "[CV 2/5] END .criterion=gini, max_depth=10, n_estimators=200; total time=   0.1s\n",
      "[CV 3/5] END .criterion=gini, max_depth=10, n_estimators=200; total time=   0.1s\n",
      "[CV 4/5] END .criterion=gini, max_depth=10, n_estimators=200; total time=   0.1s\n",
      "[CV 5/5] END .criterion=gini, max_depth=10, n_estimators=200; total time=   0.1s\n",
      "[CV 1/5] END .criterion=gini, max_depth=10, n_estimators=300; total time=   0.2s\n",
      "[CV 2/5] END .criterion=gini, max_depth=10, n_estimators=300; total time=   0.2s\n",
      "[CV 3/5] END .criterion=gini, max_depth=10, n_estimators=300; total time=   0.2s\n",
      "[CV 4/5] END .criterion=gini, max_depth=10, n_estimators=300; total time=   0.2s\n",
      "[CV 5/5] END .criterion=gini, max_depth=10, n_estimators=300; total time=   0.2s\n",
      "[CV 1/5] END .criterion=gini, max_depth=10, n_estimators=500; total time=   0.4s\n",
      "[CV 2/5] END .criterion=gini, max_depth=10, n_estimators=500; total time=   0.4s\n",
      "[CV 3/5] END .criterion=gini, max_depth=10, n_estimators=500; total time=   0.4s\n",
      "[CV 4/5] END .criterion=gini, max_depth=10, n_estimators=500; total time=   0.4s\n",
      "[CV 5/5] END .criterion=gini, max_depth=10, n_estimators=500; total time=   0.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, n_estimators=1000; total time=   1.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, n_estimators=1000; total time=   1.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, n_estimators=1000; total time=   1.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, n_estimators=1000; total time=   0.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, n_estimators=1000; total time=   0.9s\n",
      "[CV 1/5] END .criterion=gini, max_depth=15, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END .criterion=gini, max_depth=15, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END .criterion=gini, max_depth=15, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END .criterion=gini, max_depth=15, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END .criterion=gini, max_depth=15, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END .criterion=gini, max_depth=15, n_estimators=200; total time=   0.1s\n",
      "[CV 2/5] END .criterion=gini, max_depth=15, n_estimators=200; total time=   0.1s\n",
      "[CV 3/5] END .criterion=gini, max_depth=15, n_estimators=200; total time=   0.1s\n",
      "[CV 4/5] END .criterion=gini, max_depth=15, n_estimators=200; total time=   0.1s\n",
      "[CV 5/5] END .criterion=gini, max_depth=15, n_estimators=200; total time=   0.1s\n",
      "[CV 1/5] END .criterion=gini, max_depth=15, n_estimators=300; total time=   0.2s\n",
      "[CV 2/5] END .criterion=gini, max_depth=15, n_estimators=300; total time=   0.3s\n",
      "[CV 3/5] END .criterion=gini, max_depth=15, n_estimators=300; total time=   0.3s\n",
      "[CV 4/5] END .criterion=gini, max_depth=15, n_estimators=300; total time=   0.3s\n",
      "[CV 5/5] END .criterion=gini, max_depth=15, n_estimators=300; total time=   0.3s\n",
      "[CV 1/5] END .criterion=gini, max_depth=15, n_estimators=500; total time=   0.4s\n",
      "[CV 2/5] END .criterion=gini, max_depth=15, n_estimators=500; total time=   0.4s\n",
      "[CV 3/5] END .criterion=gini, max_depth=15, n_estimators=500; total time=   0.4s\n",
      "[CV 4/5] END .criterion=gini, max_depth=15, n_estimators=500; total time=   0.4s\n",
      "[CV 5/5] END .criterion=gini, max_depth=15, n_estimators=500; total time=   0.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=15, n_estimators=1000; total time=   1.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=15, n_estimators=1000; total time=   0.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=15, n_estimators=1000; total time=   1.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=15, n_estimators=1000; total time=   1.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=15, n_estimators=1000; total time=   1.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END criterion=entropy, max_depth=None, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, n_estimators=200; total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, n_estimators=200; total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, n_estimators=200; total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, n_estimators=200; total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, n_estimators=200; total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, n_estimators=300; total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, n_estimators=300; total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, n_estimators=300; total time=   0.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, n_estimators=300; total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, n_estimators=300; total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, n_estimators=500; total time=   0.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, n_estimators=500; total time=   0.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, n_estimators=500; total time=   0.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, n_estimators=500; total time=   0.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, n_estimators=500; total time=   0.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, n_estimators=1000; total time=   1.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, n_estimators=1000; total time=   1.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, n_estimators=1000; total time=   1.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, n_estimators=1000; total time=   1.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, n_estimators=1000; total time=   1.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, n_estimators=500; total time=   0.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, n_estimators=500; total time=   0.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, n_estimators=500; total time=   0.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, n_estimators=500; total time=   0.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, n_estimators=500; total time=   0.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, n_estimators=1000; total time=   1.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, n_estimators=1000; total time=   1.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, n_estimators=1000; total time=   1.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, n_estimators=1000; total time=   1.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, n_estimators=1000; total time=   1.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, n_estimators=200; total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, n_estimators=200; total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, n_estimators=200; total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, n_estimators=200; total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, n_estimators=200; total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, n_estimators=300; total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, n_estimators=300; total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, n_estimators=300; total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, n_estimators=300; total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, n_estimators=300; total time=   0.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, n_estimators=500; total time=   0.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, n_estimators=500; total time=   0.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, n_estimators=500; total time=   0.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, n_estimators=500; total time=   0.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, n_estimators=500; total time=   0.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, n_estimators=1000; total time=   1.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, n_estimators=1000; total time=   1.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, n_estimators=1000; total time=   1.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, n_estimators=1000; total time=   1.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, n_estimators=1000; total time=   1.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=15, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=15, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=15, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=15, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=15, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=15, n_estimators=200; total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=15, n_estimators=200; total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=15, n_estimators=200; total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=15, n_estimators=200; total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=15, n_estimators=200; total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=15, n_estimators=300; total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=15, n_estimators=300; total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=15, n_estimators=300; total time=   0.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=15, n_estimators=300; total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=15, n_estimators=300; total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=15, n_estimators=500; total time=   0.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=15, n_estimators=500; total time=   0.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=15, n_estimators=500; total time=   0.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=15, n_estimators=500; total time=   0.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=15, n_estimators=500; total time=   0.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=15, n_estimators=1000; total time=   1.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=15, n_estimators=1000; total time=   1.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=15, n_estimators=1000; total time=   1.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=15, n_estimators=1000; total time=   1.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=15, n_estimators=1000; total time=   1.0s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "random_forest_grid_search=GridSearchCV(random_forest,random_forest_param_grid,cv=5,n_jobs=1,verbose=5)\n",
    "random_forest_grid_search_result=random_forest_grid_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "31e72c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.842276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>entropy</td>\n",
       "      <td>10.0</td>\n",
       "      <td>500</td>\n",
       "      <td>0.842276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gini</td>\n",
       "      <td>15.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.842276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gini</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.842276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gini</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.837631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   criterion  max_depth  n_estimators  accuracy\n",
       "0       gini        NaN           100  0.842276\n",
       "33   entropy       10.0           500  0.842276\n",
       "15      gini       15.0           100  0.842276\n",
       "10      gini       10.0           100  0.842276\n",
       "14      gini       10.0          1000  0.837631"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=random_forest_grid_search_result.cv_results_\n",
    "scores_and_params= pd.DataFrame(results['params'])\n",
    "scores_and_params\n",
    "\n",
    "scores_and_params['accuracy']=pd.DataFrame(results['mean_test_score'], columns=['accuracy'])\n",
    "scores_and_params.sort_values(by= 'accuracy', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dbe4bf45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the feature importance\n",
    "%matplotlib inline\n",
    "feature_importance=pd.Series(random_forest.feature_importances_, index=final_predictors)\n",
    "feature_importance.nlargest(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5675e003",
   "metadata": {},
   "source": [
    "# ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "423793f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2),\n",
      "                   learning_rate=0.01, n_estimators=100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "DTC=tree.DecisionTreeClassifier(max_depth=2)\n",
    "adaboost_model=AdaBoostClassifier(n_estimators=100, base_estimator=DTC, learning_rate=0.01)\n",
    "print(adaboost_model)\n",
    "\n",
    "# {'base_estimator': DecisionTreeClassifier(max_depth=2), 'learning_rate': 0.01, 'n_estimators': 50}\n",
    "# {'base_estimator': DecisionTreeClassifier(max_depth=1), 'learning_rate': 1, 'n_estimators': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9cdec408",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost=adaboost_model.fit(x_train,y_train)\n",
    "adaboost_prediction= adaboost.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c2eedf40",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89        62\n",
      "           1       0.79      0.68      0.73        28\n",
      "\n",
      "    accuracy                           0.84        90\n",
      "   macro avg       0.83      0.80      0.81        90\n",
      "weighted avg       0.84      0.84      0.84        90\n",
      "\n",
      "[[57  5]\n",
      " [ 9 19]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(y_test,adaboost_prediction))\n",
    "print(metrics.confusion_matrix(y_test,adaboost_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f9c5aea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on Testing Sample Data: 0.84\n",
      "\n",
      "Accuracy values for 10-fold Cross Validation:\n",
      " [0.16666667 0.93460925 0.96703297 0.93460925 0.96619598 0.64157119\n",
      " 0.62597403 0.57647059 0.57647059 0.56298381]\n",
      "\n",
      "Final Average Accuracy of the adboost model: 0.7\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# Printing the Overall Accuracy of the model\n",
    "F1_Score=metrics.f1_score(y_test, adaboost_prediction, average='weighted')\n",
    "print('Accuracy of the model on Testing Sample Data:', round(F1_Score,2))\n",
    "\n",
    "# Importing cross validation function from sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Running 10-Fold Cross validation on a given algorithm\n",
    "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
    "adaboost_Accuracy_Values=cross_val_score(adaboost, x , y, cv=10, scoring='f1_weighted')\n",
    "print('\\nAccuracy values for 10-fold Cross Validation:\\n',adaboost_Accuracy_Values)\n",
    "print('\\nFinal Average Accuracy of the adboost model:', round(adaboost_Accuracy_Values.mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "803c1049",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_param_grid = {\n",
    "    'base_estimator': [tree.DecisionTreeClassifier(max_depth=1), tree.DecisionTreeClassifier(max_depth=2)],\n",
    "    'n_estimators': [10,50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "06231589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV 1/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=200; total time=   0.1s\n",
      "[CV 2/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=200; total time=   0.1s\n",
      "[CV 3/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=200; total time=   0.1s\n",
      "[CV 4/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=200; total time=   0.1s\n",
      "[CV 5/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.01, n_estimators=200; total time=   0.1s\n",
      "[CV 1/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.1, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.1, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.1, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.1, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.1, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.1, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.1, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.1, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.1, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.1, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.1, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.1, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.1, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.1, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.1, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.1, n_estimators=200; total time=   0.2s\n",
      "[CV 2/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.1, n_estimators=200; total time=   0.1s\n",
      "[CV 3/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.1, n_estimators=200; total time=   0.1s\n",
      "[CV 4/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.1, n_estimators=200; total time=   0.1s\n",
      "[CV 5/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=0.1, n_estimators=200; total time=   0.1s\n",
      "[CV 1/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.0, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.0, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.0, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.0, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.0, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.0, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.0, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.0, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.0, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.0, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.0, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.0, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.0, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.0, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.0, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.0, n_estimators=200; total time=   0.1s\n",
      "[CV 2/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.0, n_estimators=200; total time=   0.1s\n",
      "[CV 3/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.0, n_estimators=200; total time=   0.1s\n",
      "[CV 4/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.0, n_estimators=200; total time=   0.1s\n",
      "[CV 5/5] END base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1.0, n_estimators=200; total time=   0.2s\n",
      "[CV 1/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=200; total time=   0.1s\n",
      "[CV 2/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=200; total time=   0.1s\n",
      "[CV 3/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=200; total time=   0.1s\n",
      "[CV 4/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=200; total time=   0.1s\n",
      "[CV 5/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.01, n_estimators=200; total time=   0.1s\n",
      "[CV 1/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=200; total time=   0.1s\n",
      "[CV 2/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=200; total time=   0.1s\n",
      "[CV 3/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=200; total time=   0.1s\n",
      "[CV 4/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=200; total time=   0.2s\n",
      "[CV 5/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=200; total time=   0.2s\n",
      "[CV 1/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=200; total time=   0.2s\n",
      "[CV 2/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=200; total time=   0.1s\n",
      "[CV 3/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=200; total time=   0.1s\n",
      "[CV 4/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=200; total time=   0.1s\n",
      "[CV 5/5] END base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=200; total time=   0.1s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "adaboost_grid_search=GridSearchCV(adaboost, adaboost_param_grid,cv=5, n_jobs=1, verbose=5)\n",
    "adaboost_grid_search_result=adaboost_grid_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "879bb19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_estimator</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DecisionTreeClassifier(max_depth=2)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.837282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DecisionTreeClassifier(max_depth=2)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>0.837282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DecisionTreeClassifier(max_depth=2)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>0.832636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier(max_depth=1)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>0.832636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier(max_depth=1)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.827758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         base_estimator  learning_rate  n_estimators  accuracy\n",
       "14  DecisionTreeClassifier(max_depth=2)           0.01           100  0.837282\n",
       "13  DecisionTreeClassifier(max_depth=2)           0.01            50  0.837282\n",
       "12  DecisionTreeClassifier(max_depth=2)           0.01            10  0.832636\n",
       "3   DecisionTreeClassifier(max_depth=1)           0.01           200  0.832636\n",
       "2   DecisionTreeClassifier(max_depth=1)           0.01           100  0.827758"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=adaboost_grid_search_result.cv_results_\n",
    "scores_and_params= pd.DataFrame(results['params'])\n",
    "scores_and_params\n",
    "\n",
    "scores_and_params['accuracy']=pd.DataFrame(results['mean_test_score'], columns=['accuracy'])\n",
    "scores_and_params.sort_values(by= 'accuracy', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "40d83fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the feature importance\n",
    "%matplotlib inline\n",
    "feature_importance=pd.Series(adaboost.feature_importances_, index=final_predictors)\n",
    "feature_importance.nlargest(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bf2f0c",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9b885002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.3, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=10, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgboost_model=XGBClassifier(max_depth=6, learning_rate=0.3,n_estimators=10, objective='binary:logistic', booster='gbtree')\n",
    "print(xgboost_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "24bec07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost=xgboost_model.fit(x_train,y_train)\n",
    "xgboost_prediction=xgboost.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "546b9b50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.89        62\n",
      "           1       0.73      0.79      0.76        28\n",
      "\n",
      "    accuracy                           0.84        90\n",
      "   macro avg       0.82      0.83      0.82        90\n",
      "weighted avg       0.85      0.84      0.85        90\n",
      "\n",
      "[[54  8]\n",
      " [ 6 22]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test,xgboost_prediction))\n",
    "print(metrics.confusion_matrix(y_test, xgboost_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f6a963ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on Testing Sample Data: 0.85\n",
      "\n",
      "Accuracy values for 10-fold Cross Validation:\n",
      " [0.16666667 0.7724246  0.8692185  0.90246769 0.83744614 0.83744614\n",
      " 0.525      0.57647059 0.62597403 0.56298381]\n",
      "\n",
      "Final Average Accuracy of the xgboost model: 0.67\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# Printing the Overall Accuracy of the model\n",
    "F1_Score=metrics.f1_score(y_test, xgboost_prediction, average='weighted')\n",
    "print('Accuracy of the model on Testing Sample Data:', round(F1_Score,2))\n",
    "\n",
    "# Importing cross validation function from sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Running 10-Fold Cross validation on a given algorithm\n",
    "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
    "xgboost_Accuracy_Values=cross_val_score(xgboost, x , y, cv=10, scoring='f1_weighted')\n",
    "print('\\nAccuracy values for 10-fold Cross Validation:\\n',xgboost_Accuracy_Values)\n",
    "print('\\nFinal Average Accuracy of the xgboost model:', round(xgboost_Accuracy_Values.mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b7b2d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_param_grid = {\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'n_estimators': [10,50, 100, 200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "db4c3052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=200; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=200; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=200; total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=200; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=200; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=200; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=200; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=200; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=200; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=200; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=200; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=200; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=200; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=200; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=200; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=200; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=200; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=200; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=200; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=200; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=3, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=3, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=3, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=3, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=3, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=3, n_estimators=200; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=3, n_estimators=200; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=3, n_estimators=200; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=3, n_estimators=200; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=3, n_estimators=200; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=6, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=6, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=6, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=6, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=6, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=6, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=6, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=6, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=6, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=6, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=6, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=6, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=6, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=6, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=6, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=6, n_estimators=200; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=6, n_estimators=200; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=6, n_estimators=200; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=6, n_estimators=200; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=6, n_estimators=200; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=9, n_estimators=10; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=9, n_estimators=10; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=9, n_estimators=10; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=9, n_estimators=10; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=9, n_estimators=10; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=9, n_estimators=50; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=9, n_estimators=50; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=9, n_estimators=50; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=9, n_estimators=50; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=9, n_estimators=50; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=9, n_estimators=100; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=9, n_estimators=100; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=9, n_estimators=100; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=9, n_estimators=100; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=9, n_estimators=100; total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.3, max_depth=9, n_estimators=200; total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.3, max_depth=9, n_estimators=200; total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.3, max_depth=9, n_estimators=200; total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.3, max_depth=9, n_estimators=200; total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.3, max_depth=9, n_estimators=200; total time=   0.0s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgboost_grid_search_cv= GridSearchCV(xgboost, xgboost_param_grid, cv=5, n_jobs=1,verbose=5)\n",
    "xgboost_grid_search_cv_result=xgboost_grid_search_cv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f312f85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.30</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.847154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.30</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.837515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.01</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>0.837398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.01</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>0.837398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.832753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learning_rate  max_depth  n_estimators  accuracy\n",
       "28           0.30          6            10  0.847154\n",
       "32           0.30          9            10  0.837515\n",
       "7            0.01          6           200  0.837398\n",
       "11           0.01          9           200  0.837398\n",
       "14           0.10          3           100  0.832753"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=xgboost_grid_search_cv_result.cv_results_\n",
    "scores_and_params= pd.DataFrame(results['params'])\n",
    "scores_and_params\n",
    "\n",
    "scores_and_params['accuracy']=pd.DataFrame(results['mean_test_score'], columns=['accuracy'])\n",
    "scores_and_params.sort_values(by= 'accuracy', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "55aa9def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the feature importance\n",
    "%matplotlib inline\n",
    "feature_importance=pd.Series(xgboost.feature_importances_, index=final_predictors)\n",
    "feature_importance.nlargest(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b38b971",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "61b183e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model = KNeighborsClassifier(n_neighbors=7)\n",
    " \n",
    "#Printing all the parameters of KNN\n",
    "print(knn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c3b47c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "#Creating the model on Training Data\n",
    "KNN=knn_model.fit(x_train,y_train)\n",
    "knn_prediction=KNN.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "132071c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85        62\n",
      "           1       0.68      0.61      0.64        28\n",
      "\n",
      "    accuracy                           0.79        90\n",
      "   macro avg       0.76      0.74      0.75        90\n",
      "weighted avg       0.78      0.79      0.79        90\n",
      "\n",
      "[[54  8]\n",
      " [11 17]]\n"
     ]
    }
   ],
   "source": [
    "#Measuring accuracy on Testing Data\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, knn_prediction))\n",
    "print(metrics.confusion_matrix(y_test, knn_prediction))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7cbb7075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on Testing Sample Data: 0.79\n",
      "\n",
      "Accuracy values for 10-fold Cross Validation:\n",
      " [0.70707071 0.77333333 0.8692185  0.75421797 0.8244414  0.72486772\n",
      " 0.86136364 0.85341615 0.648      0.56298381]\n",
      "\n",
      "Final Average Accuracy of the knn model: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# Printing the Overall Accuracy of the model\n",
    "F1_Score=metrics.f1_score(y_test, knn_prediction, average='weighted')\n",
    "print('Accuracy of the model on Testing Sample Data:', round(F1_Score,2))\n",
    "\n",
    "# Importing cross validation function from sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Running 10-Fold Cross validation on a given algorithm\n",
    "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
    "knn_Accuracy_Values=cross_val_score(knn_model, x , y, cv=10, scoring='f1_weighted')\n",
    "print('\\nAccuracy values for 10-fold Cross Validation:\\n',knn_Accuracy_Values)\n",
    "print('\\nFinal Average Accuracy of the knn model:', round(knn_Accuracy_Values.mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "06cbfee0",
   "metadata": {},
   "outputs": [],
   "source": [
    " knn_param_grid={'n_neighbors': [3, 4, 5, 6, 7, 8, 9, 10, 15]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "eb2bc76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END ..................................n_neighbors=3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..................................n_neighbors=3; total time=   0.0s\n",
      "[CV 3/5] END ..................................n_neighbors=3; total time=   0.0s\n",
      "[CV 4/5] END ..................................n_neighbors=3; total time=   0.0s\n",
      "[CV 5/5] END ..................................n_neighbors=3; total time=   0.0s\n",
      "[CV 1/5] END ..................................n_neighbors=4; total time=   0.0s\n",
      "[CV 2/5] END ..................................n_neighbors=4; total time=   0.0s\n",
      "[CV 3/5] END ..................................n_neighbors=4; total time=   0.0s\n",
      "[CV 4/5] END ..................................n_neighbors=4; total time=   0.0s\n",
      "[CV 5/5] END ..................................n_neighbors=4; total time=   0.0s\n",
      "[CV 1/5] END ..................................n_neighbors=5; total time=   0.0s\n",
      "[CV 2/5] END ..................................n_neighbors=5; total time=   0.0s\n",
      "[CV 3/5] END ..................................n_neighbors=5; total time=   0.0s\n",
      "[CV 4/5] END ..................................n_neighbors=5; total time=   0.0s\n",
      "[CV 5/5] END ..................................n_neighbors=5; total time=   0.0s\n",
      "[CV 1/5] END ..................................n_neighbors=6; total time=   0.0s\n",
      "[CV 2/5] END ..................................n_neighbors=6; total time=   0.0s\n",
      "[CV 3/5] END ..................................n_neighbors=6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..................................n_neighbors=6; total time=   0.0s\n",
      "[CV 5/5] END ..................................n_neighbors=6; total time=   0.0s\n",
      "[CV 1/5] END ..................................n_neighbors=7; total time=   0.0s\n",
      "[CV 2/5] END ..................................n_neighbors=7; total time=   0.0s\n",
      "[CV 3/5] END ..................................n_neighbors=7; total time=   0.0s\n",
      "[CV 4/5] END ..................................n_neighbors=7; total time=   0.0s\n",
      "[CV 5/5] END ..................................n_neighbors=7; total time=   0.0s\n",
      "[CV 1/5] END ..................................n_neighbors=8; total time=   0.0s\n",
      "[CV 2/5] END ..................................n_neighbors=8; total time=   0.0s\n",
      "[CV 3/5] END ..................................n_neighbors=8; total time=   0.0s\n",
      "[CV 4/5] END ..................................n_neighbors=8; total time=   0.0s\n",
      "[CV 5/5] END ..................................n_neighbors=8; total time=   0.0s\n",
      "[CV 1/5] END ..................................n_neighbors=9; total time=   0.0s\n",
      "[CV 2/5] END ..................................n_neighbors=9; total time=   0.0s\n",
      "[CV 3/5] END ..................................n_neighbors=9; total time=   0.0s\n",
      "[CV 4/5] END ..................................n_neighbors=9; total time=   0.0s\n",
      "[CV 5/5] END ..................................n_neighbors=9; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=10; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=10; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=10; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=10; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=10; total time=   0.0s\n",
      "[CV 1/5] END .................................n_neighbors=15; total time=   0.0s\n",
      "[CV 2/5] END .................................n_neighbors=15; total time=   0.0s\n",
      "[CV 3/5] END .................................n_neighbors=15; total time=   0.0s\n",
      "[CV 4/5] END .................................n_neighbors=15; total time=   0.0s\n",
      "[CV 5/5] END .................................n_neighbors=15; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "knn_grid_search_cv= GridSearchCV(KNN, knn_param_grid, cv=5, n_jobs=1, verbose=5)\n",
    "knn_grid_search_result=knn_grid_search_cv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b18401f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.789779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.785134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>0.780372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.770732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>0.765854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_neighbors  accuracy\n",
       "4            7  0.789779\n",
       "2            5  0.785134\n",
       "6            9  0.780372\n",
       "0            3  0.770732\n",
       "5            8  0.765854"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=knn_grid_search_result.cv_results_\n",
    "scores_and_params= pd.DataFrame(results['params'])\n",
    "scores_and_params\n",
    "\n",
    "scores_and_params['accuracy']=pd.DataFrame(results['mean_test_score'], columns=['accuracy'])\n",
    "scores_and_params.sort_values(by= 'accuracy', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "26a2d813",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Average Accuracy of the logistic regression model: 0.8\n",
      "Final Average Accuracy of the decision tree model: 0.68\n",
      "Final Average Accuracy of the random forest model: 0.69\n",
      "Final Average Accuracy of the adaboost model: 0.7\n",
      "Final Average Accuracy of the xgboost model: 0.67\n",
      "Final Average Accuracy of the knn model: 0.76\n"
     ]
    }
   ],
   "source": [
    "print('Final Average Accuracy of the logistic regression model:', round(logistic_regression_Accuracy_Values.mean(),2))\n",
    "print('Final Average Accuracy of the decision tree model:', round(decision_tree_Accuracy_Values.mean(),2))\n",
    "print('Final Average Accuracy of the random forest model:', round(random_forest_Accuracy_Values.mean(),2))\n",
    "print('Final Average Accuracy of the adaboost model:', round(adaboost_Accuracy_Values.mean(),2))\n",
    "print('Final Average Accuracy of the xgboost model:', round(xgboost_Accuracy_Values.mean(),2))\n",
    "print('Final Average Accuracy of the knn model:', round(knn_Accuracy_Values.mean(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e455580",
   "metadata": {},
   "source": [
    "logistic regression is having the highest accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5bdbd7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, penalty='l1', solver='saga')\n"
     ]
    }
   ],
   "source": [
    "# choose parameter penalty=l1 and c=1\n",
    "print(logistic_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2c3053da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-86-2e0a3e573422>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  DataForML['DEATH_EVENT']= updated_data[target_variable]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>132.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>132.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  ejection_fraction  serum_creatinine  serum_sodium  time  DEATH_EVENT\n",
       "0  75.0               25.0               1.9         132.0     4            1\n",
       "1  55.0               38.0               1.1         136.0     6            1\n",
       "2  65.0               25.0               1.3         132.0     7            1\n",
       "3  50.0               25.0               1.9         137.0     7            1\n",
       "4  65.0               25.0               2.1         132.0     8            1"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataForML=updated_data[final_predictors]\n",
    "DataForML['DEATH_EVENT']= updated_data[target_variable]\n",
    "DataForML.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "727d15b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictors :  ['age', 'ejection_fraction', 'serum_creatinine', 'serum_sodium', 'time']\n",
      "target variable :  ['DEATH_EVENT']\n",
      "(299, 5)\n",
      "(299,)\n"
     ]
    }
   ],
   "source": [
    "# training 100% data \n",
    "print('predictors : ', final_predictors)\n",
    "print('target variable : ', [target_variable])\n",
    "x=DataForML[final_predictors].values\n",
    "y=DataForML[target_variable].values\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ee5a2a42",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, penalty='l1', solver='saga')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "reg_model= LogisticRegression(C=1,penalty='l1', solver='saga')\n",
    "print(logistic_regression_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c274e1aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaysree\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "FinalLogisticRegressionModel=reg_model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "12ecf41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle file of Predictive Model is saved at Location: C:\\Users\\Jaysree\\OneDrive\\kaggle\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Saving the Python objects as serialized files can be done using pickle library\n",
    "# Here let us save the Final Model\n",
    "with open('FinalLogisticRegressionModel.pkl', 'wb') as fileWriteStream:\n",
    "    pickle.dump(FinalLogisticRegressionModel, fileWriteStream)\n",
    "    # Don't forget to close the filestream!\n",
    "    fileWriteStream.close()\n",
    "    \n",
    "print('pickle file of Predictive Model is saved at Location:',os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e1d7d7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving this final data for reference during deployment\n",
    "DataForML.to_pickle('DataForML.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e32ba3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Function can be called from any from any front end tool/website\n",
    "def HeartFailurePrediction(InputData):\n",
    "    import pandas as pd\n",
    "    Num_Inputs=InputData.shape[0]\n",
    "    \n",
    "    # Making sure the input data has same columns as it was used for training the model\n",
    "    # Also, if standardization/normalization was done, then same must be done for new input\n",
    "    \n",
    "    # Appending the new data with the Training data\n",
    "    DataForML=pd.read_pickle('DataForML.pkl')\n",
    "    InputDataDetails=InputData.append(DataForML)\n",
    "    \n",
    "    # Treating the binary nominal variables first\n",
    "#     InputDataDetails['Married'].replace({'Yes':1, 'No':0}, inplace=True)\n",
    "#     InputLoanDetails['Education'].replace({'Graduate':1, 'Not Graduate':0}, inplace=True)\n",
    "    \n",
    "    # Generating dummy variables for rest of the nominal variables\n",
    "#     InputLoanDetails=pd.get_dummies(InputLoanDetails)\n",
    "            \n",
    "    # Maintaining the same order of columns as it was during the model training\n",
    "    Predictors=['age', 'ejection_fraction', 'serum_creatinine', 'serum_sodium', 'time']\n",
    "    \n",
    "    # Generating the input values to the model\n",
    "    X=InputDataDetails[Predictors].values[0:Num_Inputs]    \n",
    "    \n",
    "    # Generating the standardized values of X since it was done while model training also\n",
    "    X=minmax_PredictorScalarFit.transform(X)\n",
    "    \n",
    "    # Loading the Function from pickle file\n",
    "    import pickle\n",
    "    with open('FinalLogisticRegressionModel.pkl', 'rb') as fileReadStream:\n",
    "        Logistic_Regression_model=pickle.load(fileReadStream)\n",
    "        # Don't forget to close the filestream!\n",
    "        fileReadStream.close()\n",
    "            \n",
    "    # Genrating Predictions\n",
    "    Prediction=logistic_regression.predict(X)\n",
    "    PredictedStatus=pd.DataFrame(Prediction, columns=['Predicted Status'])\n",
    "    return(PredictedStatus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
